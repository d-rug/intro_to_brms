[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to brms",
    "section": "",
    "text": "Overview\nWelcome to this mini-workshop on brms! The goals of this workshop and reader are to provide a resource for you to learn about:\n\nThe package’s capabilities and utility in a Bayesian workflow\nHow brms uses Stan\nA generalized linear mixed-model example that uses brms\n\nNo prerequisites required, however it would be helpful to have an general understanding of Bayesian statistics."
  },
  {
    "objectID": "01_intro.html#bayesian-stats-is-much-more-than-just-fitting-a-model",
    "href": "01_intro.html#bayesian-stats-is-much-more-than-just-fitting-a-model",
    "title": "Background",
    "section": "Bayesian stats is much more than just fitting a model",
    "text": "Bayesian stats is much more than just fitting a model\nBayesian statistics require several steps with key decision-making moments along the way that could greatly impact your analysis. Gelman et al. (2020) outlines a workflow that helps navigate through the critical decision points:\n\nPick an initial model\nFit the model\nValidate computation\nAddress computational issues\nEvaluate and use model OR modify the model\nCompare models\n\nThis workshop covers how aspects of the brms package can be applied in each step of the Bayesian workflow. This is by no means a comprehensive list of things you should consider in your workflow, but more like a starter pack. Check out the References section of this reader for resources with a more comprehensive look at Bayesian statistics."
  },
  {
    "objectID": "02_brms.html#brms---a-package-that-can-help-you-throughout-your-bayesian-workflow",
    "href": "02_brms.html#brms---a-package-that-can-help-you-throughout-your-bayesian-workflow",
    "title": "brms in application",
    "section": "brms - a package that can help you throughout your Bayesian workflow!",
    "text": "brms - a package that can help you throughout your Bayesian workflow!\nbrms (short for Bayesian Regression Models using ‘Stan’) is a package that allows for user friendly specification of Bayesian models. The package was developed by Paul-Christian Bürkner. If you are mostly familiar with linear regression of the frequentist sort, you are in luck: the formula syntax in brms is very similar to that in lme4! The brms README file links to several resources including extensive package documentation, vignettes, and forum discussions\nIf you are new to Bayesian stats or are in need of a little brush up, check out this Bayesian Primer by Van de Schoot et al. (2021)."
  },
  {
    "objectID": "02_brms.html#install-brms",
    "href": "02_brms.html#install-brms",
    "title": "brms in application",
    "section": "Install brms",
    "text": "Install brms\nYou will first need to download brms.\n\n## Latest release from CRAN\n install.packages(\"brms\")\n\n## Or the latest development version from GitHub\n devtools::install_github(\"paul-buerkner/brms\")"
  },
  {
    "objectID": "02_brms.html#brms-the-bayesian-workflow",
    "href": "02_brms.html#brms-the-bayesian-workflow",
    "title": "brms in application",
    "section": "brms & the Bayesian workflow",
    "text": "brms & the Bayesian workflow\n\n1. Pick an initial model\nbrm is the modelling function where you can specify anything that may be relevant to your model (e.g., the response distribution, priors, group-level factors, number of chains, iterations, etc.).\nSome of the core arguments you will need to specify are:\n\nformula: this is where you specify your response and predictor variables of interest (e.g., y ~ x). This is also where you will specify your random effects (e.g., y ~ x1 + (1|x2)\ndata: specify your dataframe\nfamily: brms can handle a wide range of response distributions linear, count data, survival, response times, ordinal, zero-inflated, self-defined mixture models and much much more! This is also where you specify your link argument\n\nOther arguments you might want to specify:\n\nprior: specify the prior distributions you would like for your population-level and group-level variables. You are also not restricted to just normal distributions and specify different types including uniform, Cauchy, Gamma, etc. If you do not specify your priors, the model assumes a prior with a student_t distribution.\nwarmup: number of burn in iterations to help model find stable sampling space (default is iter/2)\niter: number of total iterations per chain (default is 2000)\nchains: number of markov chains you would like to run (default is 4)\ncores: number of cores to use when chains are running (default is 1), but you may want to specify more if your computer has capability. You can check how many cores you have by using parallel::detectCores()\ncontrol: adjust the sampling behavior of the model. I’ve mostly used this to help lower the number of divergent transitions (e.g., control = list(adapt_delta(x=.9)))\nfile: you can tell the model where to save its results (e.g., file = paste0(model,“/m_results”)\n\nAnother modelling function is brm_multiple for when you have multiple datasets that you would like to run your model over. Specifically, this is helpful if you missing data and your dataset would benefit from multiple imputation. brms interfaces nicely with the mice package which allows you to pass multiple imputed datasets into your model which then combines the posteriors draws into one model result. You can then run the rest of the brms post-processing methods as you typically would.\n\n\n2. Fit the model\n\nFigure 1. brms model fitting procedure (Burkner, 2017)\n\n\n3. Validate computation\nThis part of the workflow stresses the use of simulated data to make sure the model takes a reasonable length of time to run & passes convergence diagnostics.\nCheck out your model results: the summary function will spit out key model information like the family, formula, data and number of observations used in the model, number of samples, WAIC score, population-level effects and group-level effects (if you have any) with their respective estimates, error, 95% confidence interval, effective sample size, and Rhat score.\nEffective sample size and Rhat score are two default metrics of convergence. If your effective sample size is much lower than your number of iterations there could be efficiency issues in your chains. Secondly, if your Rhat score is > 1, then this indicates some convergence issues and therefore may not have reliable results.\n\n\n4. Address computational issues\nIn general, it is helpful to start with a simple version of the model to diagnose exactly where you are running into issues. Within your argument specification in the brm function, you can play around with the following:\n\nIf your model is taking a long time to run, try a smaller simulated dataset or a subset of your data, lower the number of iter from the default (which is 2000), or add in more informative priors than you had previously by adjusting the prior argument.\nIf your model is having convergence issues, you can try adjusting the control function to be greater than the default, which is .8, up to 1.\n\n\n\n5. Evaluate and use model OR modify the model\nThere are a couple of functions from the bayesplot package that interface with brms to evaluate your model. Most commonly, I will use the following functions to assess my model:\n\nPosterior predictive checking is one way to see how your model results compare with your observed data. You can run a posterior predictive check with the pp_check and specify several different types of checks. The most common ones I use are: “dens_overlay” and “intervals_grouped” if I am running a mixed model.\nTrace plot for your model using mcmc_plot to see if there was adequate chain mixing.\n\nAnother good test is leave-one-out cross-validation (LOOCV). LOOCV essentially checks the predictive ability of your model when part of the data is left out. This is helpful for understanding the influence of certain observations on your model fit. You can test on your model with loo.\n\n\n6. Compare models\nKeep all your model iterations. You can think of the Bayesian workflow as a process, where anything you do in this workflow is information about your data analysis.\nbrms aims to make it straightforward to adjust aspects of your model (e.g., model equation, priors, number of iterations) so that you can make comparisons between them. Once you have some models that you would like to compare, you can run loo_compare to see had the best predictive ability or run your other evaluation checks to compare fit."
  },
  {
    "objectID": "03_example.html",
    "href": "03_example.html",
    "title": "Example",
    "section": "",
    "text": "brms example\nWe are going to run through an example using orange dataset from R. For this example, I am going to load tidyverse and brms.\nWe also need to load in the actual dataset, which in this case is built into R.\nNow we can run through the Bayesian workflow process with brms to analyze this data. The two questions I have are 1) is age correlated with tree circumference and 2) does this differ depending on the tree?\nLet’s walk through the steps."
  },
  {
    "objectID": "03_example.html#pick-an-initial-model",
    "href": "03_example.html#pick-an-initial-model",
    "title": "Example",
    "section": "Pick an initial model",
    "text": "Pick an initial model\n\n## Explore shape of our data \nggplot(Orange, aes(circumference)) + \n  geom_histogram()\n\nggplot(Orange, aes(age, circumference)) + \n  geom_smooth()\n\n## Pick a model \nset.seed(1992)\nm1 <- brm(circumference ~  age, data = Orange)"
  },
  {
    "objectID": "03_example.html#validate-computation",
    "href": "03_example.html#validate-computation",
    "title": "Example",
    "section": "Validate computation",
    "text": "Validate computation\n\nsummary(m1)\n\nThe model results look good! Rhat = 1 and there is a pretty high effective sample size for the intercept and predictor. Therefore, we do not have any computational issues to address. Our model results suggest that age has a positive and significant effect on tree circumference (the 95% Bayesian credible interval is between 0.09 and 0.12). This can be interpreted as the circumference of the tree increases by 0.11 units for each one-unit increase in age.\nThe intercept shows that the estimated circumference of the tree at age 0 is 17.62, but there is a wide credible interval (0.55 to 35.12), there is quite a bit of uncertaintity with this estimate.\nSigma (family-specific parameter) tells us the variability in the response that is not explained by the model. In this case sigma is estimated to be 24.61 (3.12)."
  },
  {
    "objectID": "03_example.html#modify-model",
    "href": "03_example.html#modify-model",
    "title": "Example",
    "section": "Modify model",
    "text": "Modify model\nLet’s now make our model a little more complicated. The second question we are interested in exploring is tree-level differences.\n\nset.seed(1992)\nm2 <- brm(circumference ~ age + (1|Tree), \n                          data = Orange,\n                          warmup = 1000, #burn in period\n                          iter = 2000, # actual samples\n                          chains = 4,\n                          cores = 4,\n                          prior = c(prior(normal(0,1), class = b), # specify your mean and variance, weakly informative prior\n                                    prior(normal(0,1), class = Intercept)))\n\n## Assess model \nsummary(m2)\nloo(m2) \n\n## Posterior predictive check: \npp_check(m2, type = \"dens_overlay\", nsamples = 100) # observed data density and the posterior predictive distribution, nsamples is how many samples from the posterior distribution\npp_check(m2, type = \"stat\", stat = 'median', nsamples = 100) # calc median of the posterior predictive distribution\npp_check(m2,type = \"intervals_grouped\", group = \"Tree\") #grouped by Tree\n\n## Trace plot\nplot(m2)\n\n## Trank plot - really helpful to see chain mixing\nbayesplot::mcmc_rank_overlay(m2)\n\n## Coef plot\nmcmc_plot(m2) \n\n## Conditional effects\nconditional_effects(m2) #no group level effects without re_formula = NULL \n\n\n# Diagnosing problems\npairs(m2)\n\nAgain, model convergence and sampling efficiency look good. The estimate & error look pretty similar to m1, however the intercept is very different. We can see that the standard deviation of the Tree intercepts is quite large, 124.49, with an error of 37.55. This suggests there is quite a bit of variation between trees."
  },
  {
    "objectID": "03_example.html#compare-models",
    "href": "03_example.html#compare-models",
    "title": "Example",
    "section": "Compare models",
    "text": "Compare models\nLastly, let’s compare our models\n\nloo_compare(loo(m1), loo(m2))"
  },
  {
    "objectID": "04_resources.html#resources",
    "href": "04_resources.html#resources",
    "title": "Resources",
    "section": "Resources",
    "text": "Resources\nAlexander, Monica. (2020). Visualizing the Bayesian Workflow in R. https://www.monicaalexander.com/posts/2020-28-02-bayes_viz/\nBürkner, Paul-Christian. (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01\nBürkner, Paul-Christian (2023). brms. https://paul-buerkner.github.io/brms/\nGelman, Andrew, Vehtari, Aki, Simpson, Daniel, Margossian, Charles C., Carpenter, Bobb, Yao, Yuling, Kennedy, Lauren, Gabry, Johah, Bürkner, Paul-Christian, and Modrak, Mark (2020). Bayesian Workflow. arXiv. https://doi.org/10.48550/arXiv.2011.01808\nKurz, A Solomon (2019). Statistical Rethinking with brms, ggplot2, and the tidyverse. https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/\nMcElreath, R. (2016). Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman & Hall/CRC Press. https://xcelab.net/rm/statistical-rethinking/"
  }
]